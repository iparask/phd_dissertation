% !TEX root = main.tex

Computational sciences such as biomolecular sciences~\cite{cheatham2015impact,
dakka2018concurrent}, ecological sciences~\cite{goncalves2020sealnet,
paraskevakos2019workflow} and particle physics~\cite{atlas} execute multiple
workflows to achieve scientific insight. Users submit multiple workflows for
execution and monitor their execution while achieving a computational objective.
This way of execution multiple workflows is called a computational campaign.

For example, quantum chemistry campaigns~\cite{smith2020molssi} execute hundreds
of workflows for months and on different platforms, such as workstations, campus
and high performance computing (HPC) resources~\cite{smith2020molssi}.
Ecological sciences analyze terabytes of very high resolution satellite
imagery~\cite{goncalves2020sealnet} to derive time series of ecological
changes~\cite{paraskevakos2019workflow}. High Energy physics experiments, such
the Large Hadron Collider ATLAS experiment~\cite{atlas}, analyze petabytes of
detector or simulation data~\cite{borodin2015big} by executing campaigns with
hundreds to thousands workflows at different timescales and
frequencies~\cite{borodin2015big}.

All these use cases define and execute a computational campaign to analyze data
and achieve scientific insight. Although they serve different scientific
purposes, computational campaigns share a number of characteristics and
requirements:
\begin{inparaenum}[(1)]
    \item they are comprised of O(100) data analysis workflows;
    \item workflow requirements are not uniform across a campaign;
    \item use multiple HPC platforms;
    \item have finite allocations on said resources; and
    \item have well defined computational objectives.
\end{inparaenum}

% Why this is important
Based on the above discussion, it becomes important to effectively and
efficiently support the execution of data analysis computational campaigns on
HPC resources. This has the potential to increase overall resource utilization
across all resources that are available to a campaign. Further, increased
resource utilization will allow computational scientists to execute
computational campaigns to larger scales, leading to new scientific discoveries
and innovations. As a result, we focus our research on supporting the effective
and efficient execution of data analysis computational campaigns on HPC
resources. It is important to note that our solutions and results are agnostic
towards the scientific domain of the computational campaigns.

Computational campaigns can execute compute- and data-intensive workflows. While
compute-intensive workflows are at the epicenter of high performance scientific
computing, data-intensive workflows are not well supported on HPC resources.
Compute-intensive workflows execute either a single, very large and long-running
executable or an ensemble of smaller compute-intensive
tasks~\cite{balasubramanian2018harnessing}. Data-intensive workflows execute a
large number of short-running tasks in multiple stages which can be I/O, memory
and compute bound. As a result, a diverse set of abstractions (e.g., MapReduce
and RDDs)\mtnote{what is RDDs? Expand any acronym the first time you use it.}
and frameworks (e.g., Hadoop~\cite{hadoop} and Spark~\cite{zaharia2010spark})
have emerged to support the scalable execution of data analysis
workflows\mtnote{what is a data analysis workflow?}.

%\mtnote{We go from data-driven computation campaigns to MapReduce abstraction
%    without  connecting the two. We are missing a couple of paragraphs here.
%    What are the challenges? Once you explain those, there will be something
%    general of which the MapReduce abstraction is an example. This something
%    general will be contextualized in one of those challenges so to properly
%    introduce MapReduce.}

\mtnote{what is the difference beteween data analytics and data analysis? We
    have `data analysis workflows', `data-analysis workflows ', `data analysis',
    `data analytics', `data analytics workflows', `compute-intense workflows',
    `compute-intensive workflows', `compute intensive' (I corrected that),
    `compute-intensive applications', `data-driven compute-intensive workflows'.
    You need to tighten/clean this up}

The MapReduce~\cite{dean2004mapreduce} abstraction has been successfully used to
execute data analytics in different domains~\cite{hellerstein2012science}.
Utilizing the MapReduce abstraction to analyze data on HPC platforms has the
potential to increase resource utilization and reduce the time of completion of
data analytics. However, data analytics frameworks that implement the MapReduce
abstraction (e.g., Hadoop and Spark) mainly support cloud and not HPC platforms.
At best, current solutions allow the use of such frameworks on HPC resources in
isolation from the HPC environment. There is therefore a need for computing
environments \mtnote{what is a computing environment and how does it differ from
an HPC environment, and how does it `support' a framework?} that support
frameworks like Hadoop and Spark on HPC resources as well as compute-intensive
workflows and applications \mtnote{why do you introduce applications here? Are
workflows not enough?}. Such a computational environment can provide a solution
for executing computational campaigns, independent of the compute- or
data-intensive workflows. To the best of our knowledge, there is no solution
that provides the integrated capabilities of data analysis frameworks while
preserving the ability to execute compute-intensive applications \mtnote{from
workflows to applications?}.

Data analysis frameworks exploit task-parallelism to execute data analytics
workflows in a scalable and efficient manner. However, task-parallel frameworks
offer different abstractions and capabilities. As data analysis applications
can have different characteristics (e.g., embarrassingly parallel or
MapReduce), alternative abstractions and capabilities may offer better
performance and efficiency. In addition to performance gains, the
implementation of abstractions and capabilities by a framework has the
potential to increase the development efforts of data analysis
workflows. As a result, there is a need to understand which framework is more
suitable for performing a specific type of analysis while reducing the time
developers invest to define the analysis workflow.

Some data-analysis workflows and applications are both data- and
compute-intensive and do not necessarily conform to data-parallel abstractions.
The tasks of such workflows can be heterogeneous, implementing a diverse set of
functionalities and compute-intensive. As such, frameworks (e.g., Spark)
specifically designed for data parallelism may not support them well. Utilizing
a task-parallel framework, though, may still be beneficial in terms of
scalability, workflow execution time and resource utilization. However, the
design of the framework can significantly affect performance and resource
utilization. As a consequence, a specific design may not be well suited to
execute data analysis workflows that are compute-intensive. In addition, the
space of equivalent architectural designs to support such workflows is large
and identifying the design that can efficiently execute data-driven
compute-intensive workflows becomes important. As a result, there is a need to
understand which design is best suited to execute data-driven compute-intensive
workflows. Such an understanding will allow application developers to develop
their workflows with a framework whose design is more suited for their
application.

After establishing our understanding on how to effectively and efficiently
support the execution of data- and compute-intensive workflows on HPC
resources, we focus on supporting the execution of computational campaigns.
Currently, software systems that execute computational campaigns, campaign
managers, make assumptions about resources and the middleware they are
utilizing, are monolithic software systems, and tend to be domain specific. As
a consequence, these campaign managers cannot support computational campaigns
from different scientific domains without significantly changing their
implementations. In addition, based on the assumptions about the middleware
they cannot support workflows that do not have similar characteristics and are
developed using different workflow execution frameworks. As a result, a
campaign manager that supports the scalable execution of computational
campaigns on HPC resources and is agnostic of the middleware used and
scientific domain becomes necessary.

Finally, achieving a computational objective during the execution of a
computational campaign requires an execution plan to map workflows on multiple
HPC resources. However, actual HPC resources performance is affected by several
factors and can change significantly during the execution of a campaign. In
addition, users offer an estimation of each workflow runtime in the form of a
range of possible values. As a result, the effectiveness of a plan is not
guaranteed. It is important, then, the execution plan to efficiently map the
workflows of the campaign, so as to increase resource utilization and achieve
the objective of the campaign despite any effect from HPC resource performance
changes and runtime estimations. There is, thus, a need to understand how to
derive such an execution plan and utilize a well suited planning algorithm. As
there is a plethora of algorithms to derive an execution plan for a
campaign~\cite{lu2019review}, to the best of our knowledge, there is no
methodology to decide which algorithm is best suited given the characteristics
of the campaign and resources.

In response to these challenges, we make contributions providing the necessary
abstractions and software systems to efficiently execute data-driven workflows
on HPC resources. Further, we design a campaign manager prototype which plans
and executes computational campaigns on HPC resources. Our work is designed and
engineered to be domain and resource agnostic. The section discusses in more
detail the contributions of this dissertation.

\section{Contributions and Organization of the Dissertation}

The goal of this research is to advance the state of the art in the execution
of data-intensive scientific computational campaigns. To that extent, this
dissertation makes the following contributions.

%% First paper contributions:
In chapter~\ref{ch:pilot-data-hadoop}, we explore the integration between
Hadoop, Spark and HPC resources utilizing the
Pilot-Abstraction~\cite{luckow2012pstar} allowing applications to manage HPC
(e.g., simulations) and data-intensive application stages in a uniform way. We
evaluate the integration by measuring and characterizing the startup times of
the Pilot and tasks. In addition, we measure the performance of a well-known
algorithm to investigate the runtime trade-offs of a typical data-intensive
application.

%% Second paper contributions:
In chapter~\ref{ch:task-par}, we investigate three task-parallel frameworks,
Spark~\cite{zaharia2010spark}, Dask~\cite{rocklin2015dask} and
RADICAL-Pilot~\cite{merzky2019using}, and their suitability for implementing
MD trajectory data analysis algorithms. MD trajectories are time series of
atoms/particles positions and velocities, which are analyzed using different
statistical methods to infer certain properties, e.g., the relationship
between distinct trajectories, snapshots of a trajectory etc. As a result,
they can be considered as a representative set of scientific datasets that are
organized as time series. We characterize and explain the behavior of
different molecular dynamics analysis algorithms on these frameworks and we
provide a conceptual basis for comparing the abstractions, capabilities and
performance of these frameworks.

%% Third paper contributions:
In chapter~\ref{ch:designs}, we focus on the design of computing frameworks
that support the execution of data-driven compute intensive workflows on HPC
resources. We provide specific design guidelines for supporting data-driven,
compute-intense workflows on high-performance computing resources with a
task-based computing framework. We develop an experiment-based methodology to
compare design performance of alternative designs that does not depend on the
considered use case and computing framework.

In chapter~\ref{ch:cmanager}, we design and implement a campaign manager
prototype to plan and execute computational campaigns. We elicit three data
analysis use cases to derive the functional requirements of the campaign
manager. We provide a design and architecture based on the buildings
blocks~\cite{turilli2019middleware} so that the manager is domain and
underlying middleware agnostic.

%%Final Contributions
In chapter~\ref{ch:campaigns}, we investigate three planning algorithms,
HEFT~\cite{topcuoglu2002performance}, a genetic
algorithm~\cite{page2005algorithm}, and simple heuristic algorithm, to plan
the execution of a computational campaign on HPC resources. We develop an
experiment-based methodology to compare planning algorithms performance that
does not depend on the considered use case, computing framework and resources
used. In addition, we provide a conceptual framework for selecting planning
algorithms based on the algorithm, campaign and resources characteristics.

Chapter~\ref{ch:conclusions} concludes the dissertation with a summary of our
contributions and results. In addition, it identifies topics for further .
research and development.
%%%%%%%%%%%%%Old Text%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{Dissertation Organization}
%The dissertation is organized into 6 chapters. In
%chapter~\ref{ch:pilot-data-hadoop}, we discuss the integration between Hadoop,
%Spark and HPC resources by utilizing the Pilot-abstraction.
%Chapter~\ref{ch:task-par} discusses the investigation and comparison of three
%task-parallel frameworks and their suitability for implementing MD trajectory
%analysis algorithms. In Chapter~\ref{ch:designs}, we focus on the design of
%computing frameworks that support the execution of workflows on HPC resources
%to process large datasets.In Chapter~\ref{ch:cmanager}, we design a campaign
%manager (CM) prototype which, given a campaign, an objective, and a set of
%resources, can derive an execution plan and simulates the execution of a
%campaign. In Chapter~\ref{ch:campaigns}, we investigate algorithms which given
%a campaign, an objective and a set of constraints, will derive an execution
%plan. The dissertation concludes with Chapter~\ref{ch:conclusions} which
%discusses the conclusions of this work and identifies future work and research.
%
%
%Drug discovery campaigns, for example, screen millions of compounds to identify
%good drug candidates~\cite{dakka2018concurrent}. Usually, each compound
%screening is implemented as a workflow which computes the binding affinity of
%the compound. In addition, such applications benefit from utilizing high
%performance computing (HPC) resources and consume millions of core-hours of
%compute time~\cite{cheatham2015impact} by executing a large number of workflows
%over months. Another example of computational campaigns is
%quantum chemistry campaigns~\cite{smith2020molssi}. These campaigns usually have
%hundreds of workflows, executing for months and on different platforms, such as
%workstations, campus and HPC clusters based on workflow
%requirements~\cite{smith2020molssi}. Moreover, users prioritize some workflows
%over others and remove or add workflows or resources to the campaign during
%runtime.
%
%Ecological sciences that utilize very high resolution satellite
%imagery~\cite{goncalves2020sealnet}, require the repeated analysis of terabytes
%of data from different calendar years to derive time series of ecological
%changes. These sciences define workflows with simple or complex
%pipelines~\cite{paraskevakos2019workflow} to analyze imagery. These campaigns
%analyze imagery from different seasons, calendar years or as new imagery becomes
%available by providers. As a result, users frequently define and execute new
%workflows to achieve their scientific objective.
%
%High Energy physics experiments, such the Large Hadron Collider ATLAS
%experiment~\cite{atlas}, gather and store datasets from detectors or through
%simulations in the order of petabytes~\cite{borodin2015big}. These datasets
%are then analyzed by executing campaigns with hundreds to thousands workflows
%with different timescales and frequencies~\cite{borodin2015big}. For example,
%one of the use cases described in Ref.~\cite{borodin2015big} analyzes
%thousands of different datasets with workflows running for months every yearly
%quarter.


%Compute-based workflows are in the epicenter of scientific computing that utilizes HPC resources.
%These workflows are either defined as a single large application or as an ensemble of compute intensive tasks~\cite{balasubramanian2018harnessing}.
%In both cases, MPI is the most common programming model to implement either the whole application or the tasks of a workflows.
%In addition, HPC resources are being designed to support and optimize the execution of such workflows.

%Data-intensive workflows and applications are associated with a wide variety of characteristics and properties~\cite{fox2014towards,fox2014big}.
%Their complexity and characteristics are distinct from compute intensive applications.
%They often comprise of multiple stages such as, data ingest, pre-processing, feature-extraction and advanced analytics.
%While some of these stages are I/O bound, often with different patterns (random/sequential access), other stages are compute-/memory-bound.
%As a consequence, a diverse set of tools for data processing (e.\,g.\ MapReduce~\cite{dean2004mapreduce}, Spark~\cite{zaharia2010spark}, Dask~\cite{rocklin2015dask}), access to data sources and data formats have emerged and often need to be combined in order to support the end-to-end needs of applications.
%However, this type of tools are not fully supported on HPC resources and it becomes challenging to execute both compute and data intensive applications on the same HPC resources.
%
%There are workflows however which cannot easily classify as compute- or data-intensive.
%In fact, there are classes of scientific applications, such as bio-molecular dynamics~\cite{dror2012biomolecular} and image analysis~\cite{goncalves2020sealnet}, that have strong characteristics of both compute- and data-intensive and do not always conform to the HPC or MapReduce style of execution.
%From a workflow management framework perspective, the design and architectural space is large and the lack of performance analysis make it difficult to select among equivalent implementations.
%

%Missing computational campaign and planning capabilities

%From a design perspective, a promising approach to address these challenges is isolating tasks from execution management.
%Tasks are assumed to be self-contained programs which are executed in the operating system (OS) environment of HPC compute nodes.
%Programs implement the domain-specific functionalities required by use cases while computing frameworks implement resource acquisition, task scheduling, resource binding, and data management.

%Compared to approaches in which tasks are functions or methods, like on Spark~\cite{zaharia2010spark} or Dask~\cite{rocklin2015dask}, a program-based approach offers several benefits as, for example, simplified implementation of execution management, support of general purpose programming models, and separate programming of management and domain-specific functionalities.
%Program-based designs also impose performance limitations, including OS-mediated inter task communication and task spawning overheads, since programs execute as OS processes and do not share a memory space.

%Due to their performance limitations, program-based designs of computing frameworks are best suited to execute compute-intense workflows in which each task requires a certain amount of parallelism and runs from several minutes to hours.
%The emergence of workflows that require heterogeneous, compute-intense tasks to process large amount of data is pushing the boundaries of program-based designs, especially when scale requirements suggest the use of modern HPC infrastructures with large number of CPUs/GPUs and dedicated data facilities.

%Currently, there are software systems ( e.i., campaign managers) that are supporting the execution of computational campaigns~\cite{maeno2008panda,casajus2010dirac,qcfractal,sfiligoi2008glidein,deelman2015pegasus, salim2019balsam}.
%A commonality between current campaign managers is that they are domain specifc and make assumptions about the type of workflows to be executed.
%Another common aspect is that they are build in a monolithic approach, despite their modular design.
%Furthermore, most of the existing campaign managers do not necessarily plan the execution of the campaign, in terms of order and placement of workflows on resources.
%As a result, there is a need to design a campaign manager which, in addition to supporting the above characteristics, will be domain agnostic and provide the planning capabilities.

%Furthermore, the characteristics of the workflows that comprise such applications are different.
%Others gather data either from simulators, such as the ATLAS experiment~\cite{atlas}, or remote sensing, such as satellites~\cite{goncalves2020sealnet}, and require to analyze those data.
%Last but not least are the applications that execute workflows that are simulating systems, analyze produced data and then steer further simulations~\cite{dakka2018concurrent}.

%\subsection*{Paper 1 intro}

%The MapReduce~\cite{mapreduce} abstraction popularized by Apache Hadoop~\cite{hadoop} has been successfully used for many data-intensive applications in different domains~\cite{37684}.
%One important differentiator of Hadoop compared to HPC is the availability of many higher-level abstractions and tools for data storage, transformations and advanced analytics.
%These abstraction typically allow high-level reasoning about data parallelism without the need to manually partition data, manage tasks processing this data and collecting the results, which is required in other environments.
%Within the Hadoop ecosystem, tools like Spark~\cite{Zaharia:2010:SCC:1863103.1863113} have gained popularity by supporting specific data processing and analytics needs and are increasingly used in sciences, e.\,g.\ for DNA sequencing~\cite{Massie:EECS-2013-207}.

%Data-intensive applications are associated with a wide variety of characteristics and properties, as summarized by Fox et\,al.~\cite{bigdata-ogres,bigdata-use-cases-nist}.
%Their complexity and characteristics are fairly distinct from HPC applications.
%For example, they often comprise of multiple stages such as, data ingest, pre-processing, feature-extraction and advanced analytics.
%While some of these stages are I/O bound, often with different patterns (random/sequential access), other stages are compute-/memory-bound.
%Not surprisingly, a diverse set of tools for data processing (e.\,g.\ MapReduce, Spark RDDs), access to data sources (streaming, filesystems) and data formats (scientific data formats (HDF5), columnar formats (ORC and Parquet)) have emerged and they often need to be combined in order to support the end-to-end needs of applications.

%Some applications however, defy easy classification as data-intensive or HPC.
%In fact, there is specific interest in a class of of scientific applications, such as bio-molecular dynamics~\cite{doi:10.1146/annurev-biophys-042910-155245}, that have strong characteristics of both data-intensive and HPC.
%Bio-molecular simulations are now high-performant, reach increasing time scales and problem sizes, and thus generating immense amounts of data.
%The bulk of the data in such simulations is typically trajectory data that is time-ordered set of coordinates and velocity.
%Secondary data includes other physical parameters including different energy components.
%Often times the data generated needs to be analyzed so as to determine the next set of simulation configurations.
%The type of analysis varies from computing the higher order moments, to principal components, to time-dependent variations.

%Bio-molecular simulations are now highly performant, reaching larger problem sizes, and generating immense amounts of data.
%Often, the data generated need to be analyzed and determine the next set of simulation workflows.

%MDAnalysis~\cite{mdanalysis} and CPPTraj~\cite{doi:10.1021/ct400341p} are two tools that evolved to meet the increasing analytics demands of molecular dynamics applications; Ref~\cite{himach} represents an attempt to provide MapReduce based solutions in HPC environments.
%These tools provide powerful domain-specific analytics; a challenge is the need to scale them to high data volumes produced by molecular simulations as well as the coupling between the simulation and analytics parts.
%This points to the need for environments that support scalable data processing while preserving the ability to run simulations at the scale so as to generate the data.
%To the best of our knowledge, there does not exist a solution that provides the integrated capabilities of Hadoop and HPC.
%For example, Cray's analytics platform Urika~\footnote{http://www.cray.com/products/analytics} has Hadoop and Spark running on HPC architecture as opposed to regular clusters, but without the HPC software environment and capabilities.
%However, several applications ranging from bio-molecular simulations to epidemiology models~\cite{network1} require significant simulations interwoven with analysis capabilities such as clustering and graph analytics; in other words some stages (or parts of the same stage) of an application would ideally utilize Hadoop/Spark environments and other stages (or parts thereof) utilize HPC environments.

%MDAnalysis~\cite{michaud2011mdanalysis} and CPPTraj~\cite{roe2013ptraj} are two tools that evolved to meet the increasing analytics demands of molecular dynamics applications;
%Tools like HiMach~\cite{tu2008scalable} represent an attempt to provide MapReduce based solutions in HPC environments.
%These tools support powerful domain-specific data analysis workflows.
%A challenge is the need to scale them to high data volumes as well as couple them with simulation workflows~\cite{balasubramanian2016extasy}.
%To the best of our knowledge, there is no runtime system that provides the integrated capabilities of compute- and data- intensive workflows and applications.

%Frameworks for parallel data analysis have been created by the High Performance Computing (HPC) and Big Data communities~\cite{kamburugamuve2017anatomy}.
%MPI is the most used programming model for HPC resources.
%It assumes a SPMD execution model where each process executes the same program.
%It is highly optimized for high-performance computing and communication, which along with synchronization need explicit implementation.
%Big Data frameworks utilize higher-level MapReduce~\cite{dean2004mapreduce} programming models avoiding explicit implementations of communication.
%In addition, the MapReduce~\cite{dean2004mapreduce} abstraction makes it easy to exploit data-parallelism as required by many analysis workflows.

%Task-parallel applications involve partitioning a workload into a set of self-contained units of work.
%Based on the application, these tasks can be independent, have no inter-task communication, or coupled with varying degrees of data dependencies.
%Big Data applications exploit task parallelism for data-parallel parts (e.\,g., \texttt{map} operations), but also require coupling, for computing aggregates (the \texttt{reduce} operation).
%The MapReduce~\cite{dean2004mapreduce} abstraction popularized this execution pattern.
%Typically, a reduce operation includes shuffling intermediate data from a set of nodes to node(s) where the reduce executes.

%Spark~\cite{zaharia2010spark} and Dask~\cite{rocklin2015dask} are two Big Data frameworks.
%Both provide MapReduce abstractions and are optimized for parallel processing of large data volumes, interactive analytics and machine learning.
%Their runtime engines can automatically partition data, generate parallel tasks, and execute them on a cluster.
%In addition, Spark offers in-memory capabilities allowing caching data that are read multiple times, making it suited for interactive analytics and iterative machine learning algorithms.
%Dask also provides a MapReduce API (Dask Bags).
%Furthermore, Dask's API is more versatile, allowing custom workflows and parallel vector/matrix computations.
%Over the past decades, the High Performance Distributed Computing (HPDC) community has made significant advances in addressing resource and workload management on heterogeneous resources.
%For example, the concept of multi-level scheduling~\cite{1392910} as manifested in the decoupling of workload assignment from resource management using the concept of intermediate container jobs (also referred to as Pilot-Jobs~\cite{pstar12}) has been adopted for both HPC and Hadoop.
%Multi-level scheduling is a critical capability for data-intensive applications as often only application-level schedulers can be aware of the localities of the data sources used by a specific application.
%This motivated the extension of the Pilot-Abstraction to Pilot-Data~\cite{pilot-data-jpdc-2014} to form the central component of a resource management middleware.

%In this paper, we explore the integration between Hadoop and HPC resources utilizing the Pilot-Abstraction allowing application to manage HPC (e.\,g.\ simulations) and data-intensive application stages in a uniform way.
%We propose two extensions to RADICAL-Pilot: the ability to spawn and manage Hadoop/Spark clusters on HPC infrastructures on demand (Mode I), and to connect and utilize Hadoop and Spark clusters for HPC applications (Mode II).
%Both extensions facilitate the complex application and resource management requirements of data-intensive applications that are best met by a best-of-bread mix of Hadoop and HPC.
%By supporting these two usage modes, RADICAL-Pilot dramatically simplifies the barrier of deploying and executing HPC and Hadoop/Spark side-by-side.

%We utilize the Pilot-Abstraction~\cite{luckow2012pstar} allowing the application to manage HPC and data-intensive application stages in a uniform way.
%We propose two extensions to RADICAL-Pilot~\cite{merzky2018design}, a Pilot-Job~\cite{luckow2012pstar} runtime system designed for implementing task-parallel applications on HPC:
%\begin{inparaenum}[(i)]
%    \item the ability to spawn and manage Hadoop/Spark clusters on HPC infrastructures on demand (Mode I),
%    \item and to connect and utilize Hadoop and Spark clusters for HPC applications (Mode II)
%\end{inparaenum}.
%Both extensions facilitate the complex application and resource management requirements of data-intensive applications.
%By supporting these two usage modes, RADICAL-Pilot dramatically simplifies the barrier of deploying and executing HPC and Hadoop/Spark side-by-side.

%In addition to Spark and Dask, we investigate RADICAL-Pilot~\cite{merzky2018design}.

%MD trajectories are time series of atoms/particles positions and velocities, which are analyzed using different statistical methods to infer certain properties, e.\,g. the relationship between distinct trajectories, snapshots of a trajectory etc.
%As a result, they can be considered as a representative set of scientific datasets that are organized as time series and their analysis algorithms.

%\subsection*{Paper 2 intro}
%Frameworks for parallel data analysis have been created by the High Performance Computing (HPC) and Big Data communities~\cite{fox-2017}.
%MPI is the most used programming model for HPC resources.
%It assumes a SPMD execution model where each process executes the same program.
%It is highly optimized for high-performance computing and communication, which along with synchronization need explicit implementation.
%Big Data frameworks utilize higher-level MapReduce~\cite{mapreduce} programming models avoiding explicit implementations of communication.
%In addition, the MapReduce~\cite{mapreduce} abstraction makes it easy to exploit data-parallelism as required by many analysis applications.
%Several recent publications applied HPC techniques to advance traditional Big Data applications and Big Data frameworks~\cite{fox-2017}.

%Task-parallel applications involve partitioning a workload into a set of self-contained units of work.
%Based on the application, these tasks can be independent, have no inter-task communication, or coupled with varying degrees of data dependencies.
%Big Data applications exploit task parallelism for data-parallel parts (e.\,g., \texttt{map} operations), but also require coupling, for computing aggregates (the \texttt{reduce} operation).
%The MapReduce~\cite{mapreduce} abstraction popularized this execution pattern.
%Typically, a reduce operation includes shuffling intermediate data from a set of nodes to node(s) where the reduce executes.
%There is a recognized need to optimize communication intensive parts of Big Data frameworks using established HPC techniques for interprocess, e.\,g. shuffle operations~\cite{rdma-spark} and other forms of communication~\cite{hpc-abds,twisterNet}.

%Spark~\cite{zaharia2010spark} and Dask~\cite{rocklin2015dask} are two Big Data frameworks.
%Both provide MapReduce abstractions and are optimized for parallel processing of large data volumes, interactive analytics and machine learning.
%Their runtime engines can automatically partition data, generate parallel tasks, and execute them on a cluster.
%In addition, Spark offers in-memory capabilities allowing caching data that are read multiple times, making it suited for interactive analytics and iterative machine learning algorithms.
%Dask also provides a MapReduce API (Dask Bags).
%Furthermore, Dask's API is more versatile, allowing custom workflows and parallel vector/matrix computations.

%In this paper, we investigate the data analysis requirements of Molecular Dynamics (MD) applications.
%MD simulations are significant consumers of computing cycles, producing immense amounts of data.
%A typical $\mu sec$ MD simulation of physical system of $O(100k)$ atoms can produce from $O(10)$ to $O(1000)$ GBs of data~\cite{cheatham2015impact}.
%In addition to being the prototypical HPC application, there is increasingly a need for the analysis to be integrated with simulations and drive the next stages of execution~\cite{balasubramanian2016extasy}.
%The analysis phase must be performed quickly and efficiently in order to steer the simulations.

%We investigate three task-parallel frameworks and their suitability for implementing MD trajectory analysis algorithms.
%In addition to Spark and Dask, we investigate RADICAL-Pilot~\cite{rp-jsspp18}, a Pilot-Job~\cite{pstar12} framework designed for implementing task-parallel applications on HPC.
%We utilize MPI4py~\cite{mpi4py_paper} to provide MPI equivalent implementations of the algorithms.
%The task-parallel implementations performance and scalability compared to MPI is the basis of our analysis.
%MD trajectories are time series of atoms/particles positions and velocities, which are analyzed using different statistical methods to infer certain properties, e.\,g. the relationship between distinct trajectories, snapshots of a trajectory etc.
%As a result, they can be considered as a representative set of scientific datasets that are organized as time series and their analysis algorithms.

%\subsection*{Paper 3 intro}
%A growing number of scientific domains are adopting workflows that use multiple analysis algorithms to process a large number of images.
%The volume and scale of data processing justifies the use of parallelism, tailored programming models and high performance computing (HPC) resources.
%While these features create a large design space, the lack of architectural and performance analyses makes it difficult to chose among functionally equivalent implementations.

%In this paper we focus on the design of computing frameworks that support the execution of heterogeneous tasks on HPC resources to process large imagery datasets.
%These tasks may require one or more CPUs and GPUs, implement diverse functionalities and execute for different amounts of time.
%Typically, tasks have data dependencies and are therefore organized into workflows.
%Due to task heterogeneity, executing workflows poses the challenges of effective scheduling, correct resource binding and efficient data management.
%HPC infrastructures exacerbate these challenges by privileging the execution of single, long-running jobs.

%Queuing networks will be of limited use because they require from the user to provide a queuing network equivalent to the campaign.
%In the case the campaign contains only independent workflows, a single queuing system with multiple servers would be sufficient, but a campaign with complex dependencies between workflows may require expertise outside the user's domain to define the equivalent queuing network.
%Domain specific languages approaches either require description of the resource usage of workflows~\cite{carothers2017durango}, or execute part of the campaign to obtain an execution ``skeleton'' of the campaign~\cite{maheshwari2016workflow}.
%When executing a campaign, workflows may require days to execute to obtain execution time information, and users rarely know the resource usage of their workflows to provide accurate enough information.
%In addition, the workflows of a campaign may be different and executing some of them may not provide any information about the execution of others.

%Currently, campaign managers are making assumptions about the resources and the middleware they are utilizing, are monolithic software systems, and tend to be domain specific.
%The CM we propose to prototype will avoid these three limitations.
%Our CM will support multiple use case from different domains, such as molecular dynamics and earth sciences.
%As a result, it will be domain agnostic.
%In addition, our CM will also be designed by following the building blocks approach~\cite{turilli2019middleware}.
%In this way, it will be agnostic of the system used to manage the execution of the campaign workflows.
%This, in turn, will allow our CM to make no assumptions about the resources on which the campaign workflows will be mapped and executed.

%Execution planning for workflows are provided by several workflow execution systems, such as Pegasus~\cite{deelman2015pegasus}, and ASKALON~\cite{fahringer2005askalon}.
%Campaign management systems, such as PanDA~\cite{maeno2008panda}, do not provide a campaign planning feature.
%QCFractal~\cite{qcfractal} offers some form of planning by allowing user to specify the priority of a workflow in a campaign, but this planning does not take into account the makespan of the campaign.

%Over the past decades, the HPC community has made significant advances in addressing resource and workload management on heterogeneous resources.
%For example, the concept of multi-level scheduling~\cite{berman1996application} as manifested in decoupling workload placement from resource management using intermediate container jobs (also known as Pilot-Jobs~\cite{luckow2012pstar}) has been adopted for both HPC and Hadoop.
%Multi-level scheduling is a critical capability for data-intensive applications, as often only application-level schedulers are aware of data locality of the data used by an application.

%A growing number of scientific domains are adopting workflows that use multiple analysis algorithms to process large datasets.
%The volume and scale of data processing justifies the use of parallelism, tailored programming models and high performance computing (HPC) resources.
%While these features create a large design space, the lack of architectural and performance analyses makes it difficult to chose among functionally equivalent implementations.

%Computational campaigns enact an execution plan to allow users to achieve a computational objective under given requirements and constraints.
%A computational objective is a set of values selected by the user for a set of metrics, e.g., time to completion and throughput, which can be represented as an objective function.
%Requirements describe the minimum amount and type of resources needed to execute each workflow of the campaign, while constraints are the conditions that bound the execution, including but not limited to, resource availability, capacity or costs.
%A plan describes a sequence of actions that solves the objective function as, for example, selecting, acquiring and configuring resources, and establishing the execution order of workflows on resources.

%Planning and enacting the execution of a campaign poses four main challenges:
%\begin{inparaenum}[(i)]
%    \item evaluating the makespan of a campaign on heterogeneous and dynamic resources;
%    \item the conditions under which an execution plan performs better compared to a random resource selection;
%    \item determining a campaign execution plan on available resources that satisfies the given objective function, requirements and constraints of a campaign, while accounting for resource dynamism; and
%    \item adapting the plan in case of deviation from the objective achievement.
%\end{inparaenum}

%There are several methods and algorithms to calculate and optimize the makespan of a workflow~\cite{lu2019review}, including list-heuristics~\cite{dong2006scheduling,list_sched_wiki}, queuing networks~\cite{yao2019throughput,bao2019performance}, domain specific languages~\cite{carothers2017durango,maheshwari2016workflow}, genetic algorithms~\cite{karla2015review} and machine learning~\cite{witt2019predictive,pumma2017runtime}.