Scientific applications are benefiting from defining ensembles of computational tasks whose collective impact provide insight to the studied problem.
These tasks are organized in pipelines with well defined temporal and data dependencies, and create complex workflows with hundreds or thousands ensemble members~\cite{malawski2015algorithms,rietmann2012forward,dakka2018high}.
These workflows are either well known prior to execution, and as a result static, or change by adapting tasks to ensemble member and/or ensemble members of the workflow, thus dynamic.
Static~\cite{paraskevakos2019workflow} and dynamic~\cite{dakka2018high} workflows are used and applied in many scientific domains, e.g. ecological and biomolecular sciences. 

There is a set of scientific applications which require the execution of multiple workflows, with or without dependencies amongst them, to achieve scientific insight.
Biomolecular sciences, for example, execute workflows simulating physical systems and based on local or global analysis may require the execution of additional workflows or stopping the execution of the remaining.
Ecological sciences that use very high resolution (VHR) satellite imagery, require the analysis of TB of data from different calendar years to create time series of ecological changes.
This departs from the approach where the user submits a single workflow and wait for the final results.
Instead the user monitors the execution of several workflows, selects resources, and submits workflows for execution, while coordinating data analysis and workflow adaptation.
This way of execution is called executing a computational campaign.

Computational campaigns enact an execution plan to allow users to achieve a computational objective under given requirements and constraints.
A computational objective is a set of values selected by the user for a set of metrics, e.g., time to completion and throughput, which can be represented as an objective function.
Requirements describe the minimum amount and type of resources needed to execute each workflow of the campaign, while constraints are the conditions that bound the execution, including but not limited to, resource availability, capacity or costs.
A plan describes a sequence of actions that solves the objective function as, for example, selecting, acquiring and configuring resources, and establishing the execution order of workflows.

Several factors influence the execution plan of campaign on high performance computing resources (HPC), including resource capabilities, and resource dynamicity.
Resource capabilities refer to the type and amount of computational resources, including: 
\begin{inparaenum}[1)]
\item offered computing capacity in terms of number of CPU cores, and possible accelerators, such as GPUs,
\item offered main memory size, and
\item offered filesystem in terms of size, and whether it is shared or not.
\end{inparaenum} 
Resource dynamicity refers to the resource availability over time.
HPC resources have a broad spectrum of policies affecting their availability. 
These policies determine:
\begin{inparaenum}[1)]
\item the maximum number of compute nodes and walltime a user can request for a single job, i.e. execution,
\item the maximum number of concurrently submitted jobs (either executing or waiting in the scheduler queue), and
\item one or more usage charging models.
\end{inparaenum}
A resource is considered static when its availability remains constant over time, and dynamic when its availability changes.
The user has, based on resource capacity, and resource dynamicity to evaluate how such capacity satisfies the campaign execution over the allocation period.
These are complex and time consuming evaluations that depend on many variables, including resource usage policies, and amount of resources consumed by the campaign’s workflows.

Scientific workflows are mainly executed by utilizing dedicated workflow management frameworks (WMF), such as RADICAL-Ensemble Toolkit~\cite{balasubramanian2018harnessing}, Pegasus~\cite{deelman2015pegasus} and others.
These frameworks offer runtime capabilities, such as task execution, data dependency resolution, and workflow definition and monitoring.
Given a set of resources and a walltime, WMF try to maximize resource utilization and minimize time to completion.
WMF assume that the user selects sufficient resources and walltime to execute the workflow.
Some workflow management frameworks, such as Dask~\cite{rocklin2015dask} and Airflow~\cite{airflow}, provide capabilities to elastically adapt resources, by scaling up or down, based on the current state of execution.
In addition, some  WMFs~\cite{deelman2015pegasus} may support the concurrent execution of multiple workflows as independent entities, but not a single unified entity to achieve a single objective.
Providing a campaign manager with capabilities to plan, monitor, and adapt the execution of a campaign becomes therefore desirable.
Such a system can utilize campaign makespan calculations, alongside workflow execution capabilities, to automate campaign planning and execution. 

Planning and enacting the execution of a campaign poses four main challenges: 
\begin{inparaenum}[(i)]
\item evaluating the time needed to execute the campaign, i.e., the makespan, on possibly heterogeneous and dynamic resources;
\item understanding the conditions under which an execution plan performs better compared to a random resource selection;
\item determining a campaign execution plan on available resources that satisfies the given objective function, requirements and constraints of a campaign, while accounting for resource dynamism; and
\item adapting the plan in case of deviation from the objective achievement.
\end{inparaenum}

The makespan of a campaign is the time needed to execute all the workflows of the campaign, or alternatively, the maximum execution time among all paths throughout the campaign~\cite{chirkin2017execution}.
Calculating the makespan of a computational campaign depends on workflow characteristics, workflow dependencies, campaign dynamicity, and resource dynamicity.
Task execution time depends on parallelism, coordination between tasks, task characteristics~\cite{khoshlessan2017parallel}, the framework used to support task execution~\cite{paraskevakos2018task}, and resource dynamicity and performance variations~\cite{paraskevakos2019workflow, pouchard2019computational}.

Based on workflow tasks’ characteristics, resources may need to be configured with different execution engines.
Compute intensive tasks on HPC resources are mainly executed via OpenMP/MPI benefiting from parallelism at scale, while data intensive tasks via data parallel frameworks such as Spark~\cite{zaharia2010spark}, or Dask~\cite{rocklin2015dask}.
Traditionally, HPC resources are designed to optimize the execution of MPI tasks, leaving data-parallel frameworks largely unsupported.
In Ref.~\cite{luckow2016hadoop}, we show how a pilot-based middleware~\cite{merzky2019using} can support the efficient and scalable execution of data-parallel applications on HPC resources.
Such capabilities are necessary to support and plan the execution of a data-intensive campaign.

In this proposal, we propose a campaign manager for executing scientific computational campaigns on high performance computing resources.
This campaign manager, given a campaign, an objective and a set of constraints, will derive and enact upon an execution plan. In case, the plan deviates from achieving the objective of the campaign the campaign manager will adjust it.
During the execution of this proposal, we will:
\begin{inparaenum}[(1)]
\item an algorithm to calculate the makespan of a campaign and determine an execution plan on possibly heterogeneous and dynamic resources;
\item a software system that implements the makespan algorithm, and executes a campaign on resources; and 
\item a method to evaluate the performance of our approach compared to a random plan. 
\end{inparaenum}

The proposal is organized as follows.
Section~\ref{definitions} provides definitions for the used terminology.
Section~\ref{current_research} provides an overview of the research done to support scientific campaigns on HPC resources, as well as the research done by me this far to support data-intensive scientific campaigns on HPC resources.
Section~\ref{research} presents the research required to design and implement the proposed campaign manager.
Section~\ref{timeline} concludes the proposal by describing the proposal's timeline, significance and impact of the work, and the challenges of this work.