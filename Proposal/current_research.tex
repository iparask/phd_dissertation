Workflow execution time modeling and estimation requires a methodology of 
modeling the execution time of the individual tasks of the workflow as well as 
the overheads imposed by the used middleware. As described in \S2, a task is a 
stand alone process with well defined input, output, termination criteria and 
resource requirements. Classical analysis requires to derive the complexity of 
the algorithm used either analytically or experimentally. The complexity 
function would then provide a model of the execution time of a task. That 
requires that the task's algorithm, as well as its implementation, are well 
known. 

Individual task performance on an HPC resource depends on several factors that 
are not tunable or accessible to the user, such as shared filesystem 
performance, power management policies, and selected runtime system amongst 
others. As a result, the execution time of a task may differ significantly 
between different executions. This breaks from the expectation that a complexity 
based model can provide an accurate estimate. In addition, data intensive tasks 
are highly dependent to the filesystem performance. Thus, we model the 
execution time of a task by considering the tasks as a black box. The only 
information we have prior to execution is the input of the task, for example 
input data size or other parameters.
\gpnote{Can we model the execution time of a task as a distribution whose 
expected value is modeled by the complexity of the algorithm? Makes sense and 
it might include information of }

In Ref.~\cite{paraskevakos2019workflow}, we model the execution time of a 
data-intensive workflow as a function of their input data. Our proposed 
methodology uses a linear function to model the execution time. We fitted the 
function to the data by employing a non-linear least squares algorithm and used 
$R^{2}$ and the error of the estimation as the metrics to validate our fit. 
Figure~\ref{fig:sealfittig} shows an example from a specific fitting. 